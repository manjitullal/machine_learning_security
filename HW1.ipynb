{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjrgdxHUC3sf"
      },
      "source": [
        "# **Problem 1 [Logistic regression] - 15 points**\n",
        "\n",
        "Use an existing package of your choice to train and test a logistic regression model on the UCI Adult dataset.\n",
        "\n",
        "(a) Split the original data into 75% for training and the remaining 25% for testing, selected at random.\n",
        "Train a logistic regression model on the training set and output the following metrics on the testing\n",
        "set:\n",
        "1. Accuracy, Error;\n",
        "2. Precision, Recall, F1 score;\n",
        "3. Plot a ROC curve of the classifier and report the AUC metric.\n",
        "\n",
        "(b) Use L1 and L2 regularization with 3 different Î» parameters (0.1, 0.01, and 0.001). Write down some\n",
        "observations comparing the two regularization methods in terms of the coefficients of the models and\n",
        "accuracy metrics.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8hVL3-CDYDh"
      },
      "source": [
        "# imports libraries \n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKUF7wphGaUA"
      },
      "source": [
        "# define column names \n",
        "\n",
        "columns = [\n",
        "           'age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', \n",
        "           'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'Income'\n",
        "           ]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3gucvJODse7",
        "outputId": "1eed8d0c-0f0a-4cc7-b429-d021f16dfc03"
      },
      "source": [
        "# import data from UCI repo \n",
        "\n",
        "trainset = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data', names= columns)\n",
        "testset = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test', names= columns)\n",
        "\n",
        "print(trainset.shape)\n",
        "print(testset.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32561, 15)\n",
            "(16282, 15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "n17v4wpIFWEH",
        "outputId": "c75fb934-0965-414b-ccd5-62f4d1f4f800"
      },
      "source": [
        "trainset.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education</th>\n",
              "      <th>education-num</th>\n",
              "      <th>marital-status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>sex</th>\n",
              "      <th>capital-gain</th>\n",
              "      <th>capital-loss</th>\n",
              "      <th>hours-per-week</th>\n",
              "      <th>native-country</th>\n",
              "      <th>Income</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39</td>\n",
              "      <td>State-gov</td>\n",
              "      <td>77516</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>2174</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50</td>\n",
              "      <td>Self-emp-not-inc</td>\n",
              "      <td>83311</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>38</td>\n",
              "      <td>Private</td>\n",
              "      <td>215646</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>53</td>\n",
              "      <td>Private</td>\n",
              "      <td>234721</td>\n",
              "      <td>11th</td>\n",
              "      <td>7</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Husband</td>\n",
              "      <td>Black</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>28</td>\n",
              "      <td>Private</td>\n",
              "      <td>338409</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Wife</td>\n",
              "      <td>Black</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>Cuba</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age          workclass  fnlwgt  ... hours-per-week  native-country  Income\n",
              "0   39          State-gov   77516  ...             40   United-States   <=50K\n",
              "1   50   Self-emp-not-inc   83311  ...             13   United-States   <=50K\n",
              "2   38            Private  215646  ...             40   United-States   <=50K\n",
              "3   53            Private  234721  ...             40   United-States   <=50K\n",
              "4   28            Private  338409  ...             40            Cuba   <=50K\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "MVDJ6kZn9jkN",
        "outputId": "5205cff8-5a69-4d96-d36f-2b62cd866cd0"
      },
      "source": [
        "trainset.describe()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education-num</th>\n",
              "      <th>capital-gain</th>\n",
              "      <th>capital-loss</th>\n",
              "      <th>hours-per-week</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>32561.000000</td>\n",
              "      <td>3.256100e+04</td>\n",
              "      <td>32561.000000</td>\n",
              "      <td>32561.000000</td>\n",
              "      <td>32561.000000</td>\n",
              "      <td>32561.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>38.581647</td>\n",
              "      <td>1.897784e+05</td>\n",
              "      <td>10.080679</td>\n",
              "      <td>1077.648844</td>\n",
              "      <td>87.303830</td>\n",
              "      <td>40.437456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>13.640433</td>\n",
              "      <td>1.055500e+05</td>\n",
              "      <td>2.572720</td>\n",
              "      <td>7385.292085</td>\n",
              "      <td>402.960219</td>\n",
              "      <td>12.347429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>17.000000</td>\n",
              "      <td>1.228500e+04</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>28.000000</td>\n",
              "      <td>1.178270e+05</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>40.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>37.000000</td>\n",
              "      <td>1.783560e+05</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>40.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>48.000000</td>\n",
              "      <td>2.370510e+05</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>45.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>90.000000</td>\n",
              "      <td>1.484705e+06</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>99999.000000</td>\n",
              "      <td>4356.000000</td>\n",
              "      <td>99.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                age        fnlwgt  ...  capital-loss  hours-per-week\n",
              "count  32561.000000  3.256100e+04  ...  32561.000000    32561.000000\n",
              "mean      38.581647  1.897784e+05  ...     87.303830       40.437456\n",
              "std       13.640433  1.055500e+05  ...    402.960219       12.347429\n",
              "min       17.000000  1.228500e+04  ...      0.000000        1.000000\n",
              "25%       28.000000  1.178270e+05  ...      0.000000       40.000000\n",
              "50%       37.000000  1.783560e+05  ...      0.000000       40.000000\n",
              "75%       48.000000  2.370510e+05  ...      0.000000       45.000000\n",
              "max       90.000000  1.484705e+06  ...   4356.000000       99.000000\n",
              "\n",
              "[8 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuPHk86dKW99"
      },
      "source": [
        "# # there is a slight difference in the data of trainset and the testset\n",
        "\n",
        "# for column in categorical_columns:\n",
        "#   print(f'For the column: {column}, There are {trainset[column].value_counts().count()} unique values')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bTviSzcerMZ"
      },
      "source": [
        "# # testset\n",
        "# for column in categorical_columns:\n",
        "#   print(f'For the column: {column}, There are {testset[column].value_counts().count()} unique values')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uT-ZnWzYriJ"
      },
      "source": [
        "We see that the native country has lesser unique values that means the test data does not have all the different countries. this will be resolved through binning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9Ue5I-5ZLQk"
      },
      "source": [
        "## Bin categorical features\n",
        "\n",
        "There are more categorical columns than numeric columns. Since the categorical values have more variety binning them into a smaller bins is beneficial not only for analysis standpoint but also computationally since the categorical variables anyway has to one hot encoded."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSPtXBAjZS6G"
      },
      "source": [
        "def preprocess(data):\n",
        "  # replace workclass having ? with nan\n",
        "  data = data.replace({\"workclass\": ' ?'}, np.nan)\n",
        "\n",
        "  # workclass\n",
        "  unemployed_list = [\" Without-pay\", \" Never-worked\"]\n",
        "  gov_list = [\" Local-gov\", \" State-gov\", \" Federal-gov\"]\n",
        "\n",
        "  data.loc[(data.workclass.isin(unemployed_list)), 'workclass'] = \" Unemployed\"\n",
        "  data.loc[(data.workclass.isin(gov_list)), 'workclass'] = \" Gov\"\n",
        "\n",
        "  # education\n",
        "  hs_grad_list = [' HS-grad',' 11th',' 10th',' 9th',' 12th']\n",
        "  elementary_list = [' 1st-4th',' 5th-6th',' 7th-8th']\n",
        "\n",
        "  data.loc[(data.education.isin(hs_grad_list)), 'education'] = \" HS-grad\"\n",
        "  data.loc[(data.education.isin(elementary_list)), 'education'] = \" elementary_school\"  \n",
        "\n",
        "  # martial status \n",
        "  married_list = [\" Married-AF-spouse\", \" Married-civ-spouse\", \" Married-spouse-absent\"]\n",
        "  not_married_list = [\" Never-married\", \" Divorced\", \" Separated\"]\n",
        "\n",
        "  data.loc[(data['marital-status'].isin(married_list)), 'marital-status'] = \" Married\"\n",
        "  data.loc[(data['marital-status'].isin(not_married_list)), 'marital-status']  = \" Not-Married\"\n",
        "\n",
        "  # native country \n",
        "  data = data.replace({'native-country': ' ?'}, np.nan)\n",
        "\n",
        "  north_america_list = [\" Canada\", \" Cuba\", \" Dominican-Republic\", \" El-Salvador\", \" Guatemala\", \" Haiti\", \" Honduras\", \n",
        "                        \" Jamaica\", \" Mexico\", \" Nicaragua\", \" Outlying-US(Guam-USVI-etc)\", \" Puerto-Rico\", \" Trinadad&Tobago\", \" United-States\"]\n",
        "  asia_list = [\" Cambodia\", \" China\", \" Hong\", \" India\", \" Iran\", \" Japan\", \" Laos\", \" Philippines\", \" Taiwan\", \" Thailand\", \" Vietnam\"]\n",
        "  south_america_list = [\" Columbia\", \" Ecuador\", \" Peru\"]\n",
        "  europe_list = [\" England\", \" France\", \" Germany\", \" Greece\", \" Holand-Netherlands\", \" Hungary\", \" Ireland\", \" Italy\", \" Poland\", \" Portugal\", \" Scotland\", \" Yugoslavia\"]\n",
        "  other = [' South']\n",
        "\n",
        "  data.loc[(data['native-country'].isin(north_america_list)), 'native-country'] = ' North-America'\n",
        "  data.loc[(data['native-country'].isin(asia_list)), 'native-country'] = ' Asia'\n",
        "  data.loc[(data['native-country'].isin(south_america_list)), 'native-country'] = ' South-America'\n",
        "  data.loc[(data['native-country'].isin(europe_list)), 'native-country'] = ' Europe'\n",
        "  data.loc[(data['native-country'].isin(other)), 'native-country'] = ' Other'\n",
        "\n",
        "  # change the income to 0/1\n",
        "  data = data.replace({'Income': ' <=50K'}, 0)\n",
        "  data = data.replace({'Income': ' >50K'}, 1)\n",
        "  data = data.replace({'Income': ' <=50K.'}, 0)\n",
        "  data = data.replace({'Income': ' >50K.'}, 1)\n",
        "\n",
        "\n",
        "  # occupation\n",
        "  data = data.replace({'occupation': ' ?'}, np.nan)\n",
        "\n",
        "  return data "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQ7oZqQjYNTf"
      },
      "source": [
        "# trainset and testset \n",
        "\n",
        "trainset = preprocess(trainset)\n",
        "testset = preprocess(testset)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyI39W2mB_KG",
        "outputId": "407c5727-84c3-4020-af81-e50c66c91500"
      },
      "source": [
        "# categorical and the numeric columns \n",
        "# capital gain and capital loss values are mostly absent for majority values\n",
        "\n",
        "categorical_columns = list(trainset.select_dtypes(include=['object']).columns)\n",
        "exclude_columns = ['capital-gain', 'capital-loss', 'Income']\n",
        "numeric_columns = list(trainset.select_dtypes(include=['int64']).columns)\n",
        "\n",
        "print('Number of categorical columns', len(categorical_columns))\n",
        "print('Number of excluded columns', len(exclude_columns))\n",
        "print('Number of numeric columns', len(numeric_columns))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of categorical columns 8\n",
            "Number of excluded columns 3\n",
            "Number of numeric columns 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42Y6_WvFVAdG"
      },
      "source": [
        "# \n",
        "trainset = trainset.dropna()\n",
        "testset = testset.dropna()\n",
        "\n",
        "X_train = trainset.drop(['Income'] + exclude_columns, axis=1)\n",
        "y_train = trainset['Income']\n",
        "X_test = testset.drop(['Income'] + exclude_columns, axis=1)\n",
        "y_test = testset['Income']"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiyhayqvlKvN"
      },
      "source": [
        "# scale data \n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "def scale_data(data):\n",
        "  # scale the numerical values \n",
        "  for column in list(set(numeric_columns) - set(exclude_columns)):\n",
        "    data[column + '_s'] = scaler.fit_transform(data[column].values.reshape(-1,1))\n",
        "  return data "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0G0vVpLKjwlV"
      },
      "source": [
        "X_train = scale_data(X_train)\n",
        "X_test = scale_data(X_test)\n",
        "\n",
        "# convert the categorical columns to one hot encoding \n",
        "temp1 = pd.get_dummies(X_train[categorical_columns])\n",
        "# after convertion drop the original columns \n",
        "X_train_processed = X_train.drop(categorical_columns, axis=1)\n",
        "# also drop the numeric columns because we have the scaled columns\n",
        "X_train_processed = X_train_processed.drop(list(set(numeric_columns) - set(exclude_columns)), axis=1)\n",
        "# finally we have scaled numeric columns and one hot coded categorical columns \n",
        "X_train_processed = pd.concat([X_train_processed, temp1], axis=1)\n",
        "\n",
        "temp2 = pd.get_dummies(X_test[categorical_columns])\n",
        "X_test_processed = X_test.drop(categorical_columns, axis=1)\n",
        "X_test_processed = X_test_processed.drop(list(set(numeric_columns) - set(exclude_columns)), axis=1)\n",
        "X_test_processed = pd.concat([X_test_processed, temp2], axis=1)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "9rKWFmxYdjXc",
        "outputId": "c902ad0d-3bd1-4a60-a727-a895b006f6df"
      },
      "source": [
        "X_train_processed.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age_s</th>\n",
              "      <th>fnlwgt_s</th>\n",
              "      <th>hours-per-week_s</th>\n",
              "      <th>education-num_s</th>\n",
              "      <th>workclass_ Gov</th>\n",
              "      <th>workclass_ Private</th>\n",
              "      <th>workclass_ Self-emp-inc</th>\n",
              "      <th>workclass_ Self-emp-not-inc</th>\n",
              "      <th>workclass_ Unemployed</th>\n",
              "      <th>education_ Assoc-acdm</th>\n",
              "      <th>education_ Assoc-voc</th>\n",
              "      <th>education_ Bachelors</th>\n",
              "      <th>education_ Doctorate</th>\n",
              "      <th>education_ HS-grad</th>\n",
              "      <th>education_ Masters</th>\n",
              "      <th>education_ Preschool</th>\n",
              "      <th>education_ Prof-school</th>\n",
              "      <th>education_ Some-college</th>\n",
              "      <th>education_ elementary_school</th>\n",
              "      <th>marital-status_ Married</th>\n",
              "      <th>marital-status_ Not-Married</th>\n",
              "      <th>marital-status_ Widowed</th>\n",
              "      <th>occupation_ Adm-clerical</th>\n",
              "      <th>occupation_ Armed-Forces</th>\n",
              "      <th>occupation_ Craft-repair</th>\n",
              "      <th>occupation_ Exec-managerial</th>\n",
              "      <th>occupation_ Farming-fishing</th>\n",
              "      <th>occupation_ Handlers-cleaners</th>\n",
              "      <th>occupation_ Machine-op-inspct</th>\n",
              "      <th>occupation_ Other-service</th>\n",
              "      <th>occupation_ Priv-house-serv</th>\n",
              "      <th>occupation_ Prof-specialty</th>\n",
              "      <th>occupation_ Protective-serv</th>\n",
              "      <th>occupation_ Sales</th>\n",
              "      <th>occupation_ Tech-support</th>\n",
              "      <th>occupation_ Transport-moving</th>\n",
              "      <th>relationship_ Husband</th>\n",
              "      <th>relationship_ Not-in-family</th>\n",
              "      <th>relationship_ Other-relative</th>\n",
              "      <th>relationship_ Own-child</th>\n",
              "      <th>relationship_ Unmarried</th>\n",
              "      <th>relationship_ Wife</th>\n",
              "      <th>race_ Amer-Indian-Eskimo</th>\n",
              "      <th>race_ Asian-Pac-Islander</th>\n",
              "      <th>race_ Black</th>\n",
              "      <th>race_ Other</th>\n",
              "      <th>race_ White</th>\n",
              "      <th>sex_ Female</th>\n",
              "      <th>sex_ Male</th>\n",
              "      <th>native-country_ Asia</th>\n",
              "      <th>native-country_ Europe</th>\n",
              "      <th>native-country_ North-America</th>\n",
              "      <th>native-country_ Other</th>\n",
              "      <th>native-country_ South-America</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.301370</td>\n",
              "      <td>0.043338</td>\n",
              "      <td>0.397959</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.452055</td>\n",
              "      <td>0.047277</td>\n",
              "      <td>0.122449</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.287671</td>\n",
              "      <td>0.137244</td>\n",
              "      <td>0.397959</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.493151</td>\n",
              "      <td>0.150212</td>\n",
              "      <td>0.397959</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.150685</td>\n",
              "      <td>0.220703</td>\n",
              "      <td>0.397959</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      age_s  fnlwgt_s  ...  native-country_ Other  native-country_ South-America\n",
              "0  0.301370  0.043338  ...                      0                              0\n",
              "1  0.452055  0.047277  ...                      0                              0\n",
              "2  0.287671  0.137244  ...                      0                              0\n",
              "3  0.493151  0.150212  ...                      0                              0\n",
              "4  0.150685  0.220703  ...                      0                              0\n",
              "\n",
              "[5 rows x 54 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3uagAHtV2xM"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27mqDvKuT8ew",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b8ca16f-0272-43b0-80b5-63d307eb2ac4"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "# C value determines the regularization and if the value of C is very high the lambda will be close to 0 making the loss function close to standard without regularization\n",
        "# default max iteration is 100 and the algorithm does not converge within limit \n",
        "\n",
        "# fit the model on train set \n",
        "model = LogisticRegression(C=1e42, max_iter=1000)\n",
        "model.fit(X_train_processed, y_train)\n",
        "\n",
        "# test the model on test set \n",
        "y_pred = model.predict(X_test_processed)\n",
        "accuracy_score(y_pred, y_test)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8302788844621514"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDbIBeARMrHl",
        "outputId": "fad99a0f-c486-41db-e5b4-774beaaf467e"
      },
      "source": [
        "# log likelihood \n",
        "from sklearn.metrics import log_loss\n",
        "log_loss(y_test, y_pred)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.862009992281244"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwMGaNfeKdD8",
        "outputId": "a4aec898-c0cc-46b1-d19e-6b7409f5fa82"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.87      0.92      0.89     11360\n",
            "         1.0       0.69      0.57      0.62      3700\n",
            "\n",
            "    accuracy                           0.83     15060\n",
            "   macro avg       0.78      0.74      0.76     15060\n",
            "weighted avg       0.82      0.83      0.82     15060\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "8V2LgUFFNC1P",
        "outputId": "31325856-adf7-4d79-836e-29201a2c2065"
      },
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "probs = model.predict_proba(X_test_processed)[:,1]\n",
        "fpr, tpr, _ = metrics.roc_curve(y_test,  probs)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eb1PrkGOREXR"
      },
      "source": [
        "Testing various regularization parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9OAxU5lRInZ",
        "outputId": "541795c5-8725-4c6b-95ae-e8ec8114c979"
      },
      "source": [
        "# L1 penalty\n",
        "C = [.1, .01, .001]\n",
        "\n",
        "for c in C:\n",
        "    clf = LogisticRegression(penalty='l1', C=c, solver='liblinear')\n",
        "    clf.fit(X_train_processed, y_train)\n",
        "    print('C:', c)\n",
        "    print('Coefficient of each feature:', clf.coef_)\n",
        "    print('Training accuracy:', clf.score(X_train_processed, y_train))\n",
        "    print('Test accuracy:', clf.score(X_test_processed, y_test))\n",
        "    print('')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C: 0.1\n",
            "Coefficient of each feature: [[ 2.63768498  0.34301998  2.01379179  3.86529239 -0.01925367  0.\n",
            "   0.22764566 -0.40489026  0.         -0.26800028 -0.03657819  0.\n",
            "   0.04091308 -0.12077208  0.08271258  0.          0.44560539 -0.00779559\n",
            "   0.          0.         -0.97681853 -0.47793205  0.          0.\n",
            "   0.          0.77694832 -0.88940293 -0.65883768 -0.31329719 -0.92469077\n",
            "   0.          0.46099355  0.27704242  0.24511009  0.490495   -0.11863697\n",
            "   0.81917018  0.         -0.19805841 -1.08240455 -0.05143497  2.04841667\n",
            "   0.          0.          0.         -0.00954276  0.12529613 -0.83557379\n",
            "   0.          0.          0.          0.          0.         -0.10590709]]\n",
            "Training accuracy: 0.8299847490219482\n",
            "Test accuracy: 0.8308100929614873\n",
            "\n",
            "C: 0.01\n",
            "Coefficient of each feature: [[ 0.12655866  0.          0.37795227  1.36388542  0.         -0.06552743\n",
            "   0.0715443  -0.08687328  0.          0.          0.          0.\n",
            "   0.         -0.73329656  0.08083476  0.          0.         -0.32213261\n",
            "  -0.44837823  0.12779682 -1.72436978 -0.22220963  0.          0.\n",
            "   0.          0.80614667 -0.06378761 -0.00603251  0.         -0.52207218\n",
            "   0.          0.55336842  0.          0.14061047  0.          0.\n",
            "   0.01372514  0.          0.         -0.75195692  0.          0.52985167\n",
            "   0.          0.          0.          0.          0.         -0.64333714\n",
            "   0.          0.          0.          0.          0.          0.        ]]\n",
            "Training accuracy: 0.8201379218884689\n",
            "Test accuracy: 0.8256972111553785\n",
            "\n",
            "C: 0.001\n",
            "Coefficient of each feature: [[ 0.          0.          0.          0.          0.         -0.08741588\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.         -0.52700016  0.          0.          0.          0.\n",
            "   0.          0.         -1.56997679  0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.        ]]\n",
            "Training accuracy: 0.7510775147536636\n",
            "Test accuracy: 0.7543160690571049\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtPc-PdvRlLP",
        "outputId": "dd0b11e5-f5b6-474c-c511-6e8782d6b387"
      },
      "source": [
        "# L2 penalty\n",
        "C = [.1, .01, .001]\n",
        "\n",
        "for c in C:\n",
        "    clf = LogisticRegression(penalty='l2', C=c, solver='liblinear')\n",
        "    clf.fit(X_train_processed, y_train)\n",
        "    print('C:', c)\n",
        "    print('Coefficient of each feature:', clf.coef_)\n",
        "    print('Training accuracy:', clf.score(X_train_processed, y_train))\n",
        "    print('Test accuracy:', clf.score(X_test_processed, y_test))\n",
        "    print('')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C: 0.1\n",
            "Coefficient of each feature: [[ 2.2453329   0.51149765  1.80840194  1.60771498 -0.37372248 -0.32925038\n",
            "  -0.01906782 -0.72145144 -0.25596595 -0.43335439 -0.34351959  0.03596874\n",
            "   0.62515503 -0.72620601  0.30561489 -0.30254188  0.82082841 -0.43175135\n",
            "  -1.24965192  0.01602806 -1.09260841 -0.62287772 -0.0539683  -0.03497716\n",
            "  -0.05473197  0.74168881 -0.91938138 -0.77943173 -0.4196648  -0.99522344\n",
            "  -0.42895319  0.41654503  0.32426443  0.22121816  0.48665768 -0.2035002\n",
            "   0.24580284 -0.46993751 -0.78443998 -1.53149977 -0.55209029  1.39270664\n",
            "  -0.4722138  -0.19159622 -0.29375615 -0.56679438 -0.17509752 -1.24657421\n",
            "  -0.45288386 -0.30843536 -0.03698996 -0.16205136 -0.55354549 -0.63843589]]\n",
            "Training accuracy: 0.8298189775213846\n",
            "Test accuracy: 0.8304780876494023\n",
            "\n",
            "C: 0.01\n",
            "Coefficient of each feature: [[ 0.69303993  0.02548344  0.7655999   0.64046507 -0.21059986 -0.28175858\n",
            "   0.16352673 -0.45442099 -0.02949818 -0.1947265  -0.20260703  0.18207933\n",
            "   0.4302155  -0.76265535  0.42170496 -0.06387249  0.56850674 -0.39255865\n",
            "  -0.79883739  0.43679188 -0.9841325  -0.26541026 -0.10180622 -0.0059639\n",
            "  -0.1149845   0.69418103 -0.51932489 -0.48922896 -0.36171931 -0.71174787\n",
            "  -0.07931708  0.44941124  0.14326344  0.1850845   0.2572594  -0.15785776\n",
            "   0.22976992 -0.23921394 -0.33549398 -0.9004771  -0.33193126  0.76459548\n",
            "  -0.15211236 -0.19139523 -0.20584368 -0.1713521  -0.09204751 -0.68189162\n",
            "  -0.13085927 -0.19074629 -0.08488564 -0.29677993 -0.0965723  -0.14376672]]\n",
            "Training accuracy: 0.8263709303096611\n",
            "Test accuracy: 0.8293492695883135\n",
            "\n",
            "C: 0.001\n",
            "Coefficient of each feature: [[ 0.04153928 -0.03423104  0.12114771  0.14288159 -0.04869185 -0.2658576\n",
            "   0.10208358 -0.1329224  -0.00359853 -0.02799338 -0.03934122  0.20203238\n",
            "   0.10186547 -0.52532683  0.2115861  -0.00989383  0.14440721 -0.20675473\n",
            "  -0.19956794  0.39070613 -0.67497064 -0.06472227 -0.11609185 -0.00105066\n",
            "  -0.12287242  0.34541784 -0.14066419 -0.14391784 -0.14788042 -0.27316244\n",
            "  -0.0154562   0.26378982  0.00820903  0.03735045  0.03664764 -0.07930556\n",
            "   0.2836993  -0.21401418 -0.08967824 -0.35123557 -0.17556305  0.19780495\n",
            "  -0.03004524 -0.05034179 -0.13043991 -0.0316336  -0.10652624 -0.31566068\n",
            "  -0.03332611 -0.03634114 -0.01552233 -0.26554504 -0.01164106 -0.01993721]]\n",
            "Training accuracy: 0.8150653139712221\n",
            "Test accuracy: 0.8152722443559097\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jh2i6ReAUVaQ"
      },
      "source": [
        "# Problem 2 [Comparing classifiers] - 30 points\n",
        "\n",
        "In this problem, you will use existing packages of your choice for training and testing various classifiers, and then compare them. You will use the same UCI Adult dataset. You can use the same training and testing data as in Problem 1.\n",
        "\n",
        "(a) Train a linear SVM model and report the accuracy, precision, recall, and F1 score metrics.\n",
        "\n",
        "(b) Select a kernel function for non-linear SVM and report the same metrics as in part (a).\n",
        "\n",
        "(c) Train a random forest classifier, and vary the number of trees in the model. Select three values for the number of trees and report the same metrics as in part (a).\n",
        "\n",
        "(d) Write down some observations on comparing the following models: logistic regression, linear SVM, kernel SVM, and random forest."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awbAmM2xWDAb"
      },
      "source": [
        "## SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQDqgeugUkIB",
        "outputId": "7a125248-0ffc-4e59-c89d-9a94548400ff"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "# fit the model on train set \n",
        "model = LinearSVC()\n",
        "model.fit(X_train_processed, y_train)\n",
        "\n",
        "# test the model on test set \n",
        "y_pred = model.predict(X_test_processed)\n",
        "accuracy_score(y_pred, y_test)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8306772908366534"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GExvXtCwWPug",
        "outputId": "3dd773a5-2274-4f11-b3d8-3e11490f49e9"
      },
      "source": [
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.86      0.92      0.89     11360\n",
            "         1.0       0.69      0.56      0.62      3700\n",
            "\n",
            "    accuracy                           0.83     15060\n",
            "   macro avg       0.78      0.74      0.75     15060\n",
            "weighted avg       0.82      0.83      0.82     15060\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFZi1GtxWXYJ"
      },
      "source": [
        "## SVM - Non Linear "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6sKCjrOWWg3",
        "outputId": "2f198cf3-ccee-4c08-c5ff-30a9ed67dd10"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# fit the model on train set \n",
        "model = SVC(kernel = 'rbf', random_state = 0)\n",
        "model.fit(X_train_processed, y_train)\n",
        "\n",
        "# test the model on test set \n",
        "y_pred = model.predict(X_test_processed)\n",
        "accuracy_score(y_pred, y_test)\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8291500664010624"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rbf9aIKLUUQR",
        "outputId": "bbcf04a2-9189-404f-edf4-6ff4aedf3972"
      },
      "source": [
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.86      0.92      0.89     11360\n",
            "         1.0       0.69      0.55      0.61      3700\n",
            "\n",
            "    accuracy                           0.83     15060\n",
            "   macro avg       0.78      0.73      0.75     15060\n",
            "weighted avg       0.82      0.83      0.82     15060\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEWYBGdlYIhx"
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKlh8HESYM4l",
        "outputId": "f8aef3de-13c9-4735-db3b-d54634a6a91a"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# fit the model on train set \n",
        "base_model = RandomForestClassifier(random_state=0)\n",
        "base_model.fit(X_train_processed, y_train)\n",
        "\n",
        "# test the model on test set \n",
        "y_pred = base_model.predict(X_test_processed)\n",
        "accuracy_score(y_pred, y_test)\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8164674634794157"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8nW_5syYG2A",
        "outputId": "d76becd3-6a92-4951-d372-f681f6a24e3e"
      },
      "source": [
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.86      0.90      0.88     11360\n",
            "         1.0       0.65      0.56      0.60      3700\n",
            "\n",
            "    accuracy                           0.82     15060\n",
            "   macro avg       0.75      0.73      0.74     15060\n",
            "weighted avg       0.81      0.82      0.81     15060\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "td97jA-OjaRQ",
        "outputId": "d5b945a1-b574-4e6e-a686-87bd720fdb9c"
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 500, num = 10)]\n",
        "max_features = ['auto', 'sqrt']\n",
        "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
        "max_depth.append(None)\n",
        "min_samples_split = [2, 5, 10]\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "bootstrap = [True, False]\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'bootstrap': bootstrap}\n",
        "\n",
        "model = RandomForestClassifier(random_state=0)\n",
        "rf_random = RandomizedSearchCV(estimator = model, param_distributions = random_grid, n_iter = 20, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
        "rf_random.fit(X_train_processed, y_train)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  2.8min\n",
            "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  5.2min finished\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3, error_score=nan,\n",
              "                   estimator=RandomForestClassifier(bootstrap=True,\n",
              "                                                    ccp_alpha=0.0,\n",
              "                                                    class_weight=None,\n",
              "                                                    criterion='gini',\n",
              "                                                    max_depth=None,\n",
              "                                                    max_features='auto',\n",
              "                                                    max_leaf_nodes=None,\n",
              "                                                    max_samples=None,\n",
              "                                                    min_impurity_decrease=0.0,\n",
              "                                                    min_impurity_split=None,\n",
              "                                                    min_samples_leaf=1,\n",
              "                                                    min_samples_split=2,\n",
              "                                                    min_weight_fraction_leaf=0.0,\n",
              "                                                    n_estimators=100,\n",
              "                                                    n_jobs...\n",
              "                   iid='deprecated', n_iter=20, n_jobs=-1,\n",
              "                   param_distributions={'bootstrap': [True, False],\n",
              "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
              "                                                      70, 80, 90, 100, 110,\n",
              "                                                      None],\n",
              "                                        'max_features': ['auto', 'sqrt'],\n",
              "                                        'min_samples_leaf': [1, 2, 4],\n",
              "                                        'min_samples_split': [2, 5, 10],\n",
              "                                        'n_estimators': [10, 64, 118, 173, 227,\n",
              "                                                         282, 336, 391, 445,\n",
              "                                                         500]},\n",
              "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
              "                   return_train_score=False, scoring=None, verbose=2)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYHAOQlrtxiS",
        "outputId": "aa27c62a-2b50-4dbb-f292-e0a369c231fa"
      },
      "source": [
        "y_pred = base_model.predict(X_test_processed)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.86      0.90      0.88     11360\n",
            "         1.0       0.65      0.56      0.60      3700\n",
            "\n",
            "    accuracy                           0.82     15060\n",
            "   macro avg       0.75      0.73      0.74     15060\n",
            "weighted avg       0.81      0.82      0.81     15060\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzEDuwa-uclO",
        "outputId": "230cce52-e5ac-4f5d-b902-3f25daf1c361"
      },
      "source": [
        "best_random = rf_random.best_estimator_\n",
        "y_pred = best_random.predict(X_test_processed)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.87      0.92      0.90     11360\n",
            "         1.0       0.71      0.57      0.63      3700\n",
            "\n",
            "    accuracy                           0.84     15060\n",
            "   macro avg       0.79      0.75      0.76     15060\n",
            "weighted avg       0.83      0.84      0.83     15060\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzBHQaabvAHO",
        "outputId": "382e5fad-7e9b-4527-e4c9-50ea4f037d7b"
      },
      "source": [
        "base_model.get_params"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method BaseEstimator.get_params of RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
              "                       warm_start=False)>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1y_MBy9tuqa-",
        "outputId": "5d5e8071-b075-49ef-94c6-17c635700b87"
      },
      "source": [
        "best_random.get_params"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method BaseEstimator.get_params of RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=4, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=391,\n",
              "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
              "                       warm_start=False)>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSXigjDZS7fy"
      },
      "source": [
        "#Problem 3 [Gradient computation] 25 points\n",
        "\n",
        "In this problem, you will derive the gradient descent update rules for a logistic regression model and for a\n",
        "simple neural network model with one hidden layer.\n",
        "\n",
        "(a) Consider a logistic regression model hÎ¸(x) = g(Î¸T x), where g(z) = 1\n",
        "1+eâz is the sigmoid function.\n",
        "Consider the cross-entropy objective for training data (xi, yi), i = 1, . . . ,\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "Write down the gradient update rule for the model parameter Î¸ if it is trained with gradient descent.\n",
        "\n",
        "(b) Consider a feed-forward neural network with one hidden layer and the sigmoid activation function.\n",
        "We will use the same cross-entropy objective as in part (a). Write down the update rules for model\n",
        "parameters during backpropagation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHxC_uFrTd3z"
      },
      "source": [
        "# Problem 4 [Backpropagation implementation] 30 points\n",
        "\n",
        "In this problem, you will implement your own backpropagation procedure for a neural network with one\n",
        "hidden layer.\n",
        "\n",
        "(a) Implement the backpropagation algorithm you derived in Problem 3, part (b), for a neural network with a single hidden layer, sigmoid activation, and cross-entropy objective.\n",
        "\n",
        "(b) Train the network for 20 epochs using mini-batch SGD with batches of size 128 and plot a graph on how the accuracy and cross-entropy loss function (computed on the testing set) vary with the number of epochs. You can select and fix the number of neurons in the hidden layer and the learning rate.\n",
        "\n",
        "(c) Vary the learning rate and report results for different learning rates (at least 3 different values). Discuss\n",
        "how the metrics change as a function of learning rate and number of epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9DP61NLcX7k",
        "outputId": "6ed69cfa-87df-404f-c566-eb9085b01692"
      },
      "source": [
        "# data for NN training \n",
        "\n",
        "NN_X_train = X_train_processed.transpose()\n",
        "NN_y_train = y_train.values.reshape(-1,1).transpose()\n",
        "NN_X_test = X_test_processed.transpose()\n",
        "NN_y_test = y_test.values.reshape(-1,1).transpose()\n",
        "\n",
        "\n",
        "n_x = NN_X_train.shape[0]\n",
        "n_y = NN_y_train.shape[0]\n",
        "n_h = 4\n",
        "m = NN_y_train.shape[1]  \n",
        "\n",
        "# #test\n",
        "# n_x = 2\n",
        "# n_y = 1\n",
        "# n_h = 4\n",
        "# m = 400\n",
        "\n",
        "print ('The size of input is: ' + str(n_x))\n",
        "print ('The size of hidden layer is: ' + str(n_h))\n",
        "print ('The size of output is: ' + str(n_y))\n",
        "print ('training examples!', m)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The size of input is: 54\n",
            "The size of hidden layer is: 4\n",
            "The size of output is: 1\n",
            "training examples! 30162\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zSJC1a4vJhN"
      },
      "source": [
        "def sigmoid(z):\n",
        "    return 1/(1 + np.exp(-z))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZhDk8dAkRRk"
      },
      "source": [
        "def initialize_parameters(n_x, n_h, n_y):\n",
        "  np.random.seed(2)\n",
        "\n",
        "  W1 = np.random.randn(n_h, n_x)*0.01\n",
        "  b1 = np.zeros(shape=(n_h, 1))\n",
        "  W2 = np.random.randn(n_y, n_h)*0.01\n",
        "  b2 = np.zeros(shape=(n_y, 1))\n",
        "\n",
        "  parameters = {\"W1\": W1,\n",
        "                \"b1\": b1,\n",
        "                \"W2\": W2,\n",
        "                \"b2\": b2}\n",
        "  \n",
        "  return parameters"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhVLSSQAnXsZ"
      },
      "source": [
        "def forward_propogation(X, parameters):\n",
        "  # get the parameters from the parameters dictionary\n",
        "  W1 = parameters['W1']\n",
        "  b1 = parameters['b1']\n",
        "  W2 = parameters['W2']\n",
        "  b2 = parameters['b2']\n",
        "\n",
        "  # forward propogation\n",
        "  Z1 = np.dot(W1, X) + b1\n",
        "  A1 = np.tanh(Z1)\n",
        "  Z2 = np.dot(W2, A1) + b2\n",
        "  A2 = sigmoid(Z2)\n",
        "\n",
        "  assert(A2.shape == (1, X.shape[1]))\n",
        "    \n",
        "  cache = {\"Z1\": Z1,\n",
        "            \"A1\": A1,\n",
        "            \"Z2\": Z2,\n",
        "            \"A2\": A2}\n",
        "  \n",
        "  return A2, cache"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLNyuV3b3c-_"
      },
      "source": [
        "# # test \n",
        "# X = np.random.randn(2,400)\n",
        "# parameters = initialize_parameters(n_x, n_h, n_y)\n",
        "# A2, cache = forward_propogation(X, parameters)"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pGmrJXyo9sr"
      },
      "source": [
        "def compute_loss(A2, Y, parameters):\n",
        "  m = Y.shape[1]\n",
        "\n",
        "  # logistic regression loss function \n",
        "\n",
        "  logprobs = np.log(A2)*Y + (1 - Y)*np.log(1 - A2)\n",
        "  cost = - np.sum(logprobs) / m\n",
        "\n",
        "  return np.squeeze(cost)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gt5CKw1n3-cZ"
      },
      "source": [
        "# # test \n",
        "# Y = np.random.choice([0, 1], size=m, p=[.5, .5]).reshape(-1,1).transpose()\n",
        "# compute_loss(A2, Y, parameters)"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6pWoQklp94P"
      },
      "source": [
        "def backward_propogation(parameters, cache, X, Y):\n",
        "  # get the parameters from the dictionary\n",
        "\n",
        "  m = Y.shape[1]\n",
        "\n",
        "  W1 = parameters['W1']\n",
        "  W2 = parameters['W2']\n",
        "\n",
        "  A1 = cache['A1']\n",
        "  A2 = cache['A2']\n",
        "\n",
        "  # back propogation \n",
        "\n",
        "  dZ2= A2 - Y\n",
        "  dW2 = (1 / m) * np.dot(dZ2, A1.T)\n",
        "  db2 = (1 / m) * np.sum(dZ2, axis=1, keepdims=True)\n",
        "  dZ1 = np.dot(W2.T, dZ2)* (1 - np.power(A1, 2))\n",
        "  dW1 = (1 / m) * np.dot(dZ1, X.T)\n",
        "  db1 = (1 / m) * np.sum(dZ1, axis=1, keepdims=True)\n",
        "  \n",
        "  grads = {\"dW1\": dW1,\n",
        "            \"db1\": db1,\n",
        "            \"dW2\": dW2,\n",
        "            \"db2\": db2}\n",
        "  \n",
        "  return grads\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1SM8Rtd7Kr5"
      },
      "source": [
        "# # test\n",
        "# grads = backward_propogation(parameters, cache, X, Y)\n",
        "# grads"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4e-GqApUmYmo"
      },
      "source": [
        "def parameters_update(parameters, grads, learning_rate=2):\n",
        "  W1 = parameters['W1']\n",
        "  b1 = parameters['b1']\n",
        "  W2 = parameters['W2']\n",
        "  b2 = parameters['b2']\n",
        "\n",
        "  dW1 = grads['dW1']\n",
        "  db1 = grads['db1']\n",
        "  dW2 = grads['dW2']\n",
        "  db2 = grads['db2']\n",
        "\n",
        "  W1 = W1 - learning_rate * dW1\n",
        "  b1 = b1 - learning_rate * db1\n",
        "  W2 = W2 - learning_rate * dW2\n",
        "  b2 = b2 - learning_rate * db2\n",
        "      \n",
        "  parameters = {\"W1\": W1,\n",
        "                \"b1\": b1,\n",
        "                \"W2\": W2,\n",
        "                \"b2\": b2}\n",
        "  \n",
        "  return parameters"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IDVwdUUtT2L"
      },
      "source": [
        "# with mini batch SGD \n",
        "\n",
        "parameters = initialize_parameters(n_x, n_h, n_y)\n",
        "W1 = parameters['W1']\n",
        "b1 = parameters['b1']\n",
        "W2 = parameters['W2']\n",
        "b2 = parameters['b2']\n",
        "\n",
        "def nn(parameters, X, Y):     \n",
        "  A2, cache = forward_propogation(X, parameters)\n",
        "  cost = compute_loss(A2, Y, parameters)  \n",
        "  grads = backward_propogation(parameters, cache, X, Y)\n",
        "  parameters = parameters_update(parameters, grads)\n",
        "  return parameters, cost"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5k8x6j5LuRo9"
      },
      "source": [
        "#parameters = nn(NN_X_train, NN_y_train, num_iterations=1000)"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czAuUh5rEalp"
      },
      "source": [
        "def predict(parameters, X):\n",
        "  A2, cache = forward_propogation(X, parameters)\n",
        "  predictions = np.where(A2 >= 0.5, 1, 0)\n",
        "  return predictions"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZL-De2B9WqJ"
      },
      "source": [
        "n_iter = 20\n",
        "import sklearn \n",
        "\n",
        "def mini_batch(parameters, X_train, y_train, minibatch_size):\n",
        "    overall_loss = []\n",
        "    overall_accuracy = []\n",
        "    for iter in range(n_iter):        \n",
        "        X_train, y_train = sklearn.utils.shuffle(X_train, y_train)\n",
        "        for i in range(0, X_train.shape[0], minibatch_size):\n",
        "            X_train_mini = X_train[i:i + minibatch_size]\n",
        "            y_train_mini = y_train[i:i + minibatch_size]\n",
        "            parameters, cost = nn(parameters, X_train_mini.transpose(), y_train_mini.transpose())\n",
        "            overall_loss.append(cost)\n",
        "\n",
        "            # get the accuracy \n",
        "            NN_y_pred = predict(parameters, NN_X_test)\n",
        "            accuracy = accuracy_score(NN_y_pred.squeeze(), y_test)\n",
        "            overall_accuracy.append(accuracy)\n",
        "\n",
        "            if i% 100 == 0:\n",
        "              print (\"Cost after iteration %i: %f\" % (iter, cost))\n",
        "    return parameters, overall_loss, overall_accuracy"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dmvwv0S5AMne",
        "outputId": "81e3522c-06a0-42d2-e39a-30b97ba280d2"
      },
      "source": [
        "minibatch_size = 128\n",
        "parameters, overall_loss, overall_accuracy = mini_batch(parameters, NN_X_train.transpose(), NN_y_train.transpose(), minibatch_size)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cost after iteration 0: 0.374554\n",
            "Cost after iteration 0: 0.335027\n",
            "Cost after iteration 0: 0.279698\n",
            "Cost after iteration 0: 0.408980\n",
            "Cost after iteration 0: 0.296503\n",
            "Cost after iteration 0: 0.347480\n",
            "Cost after iteration 0: 0.447948\n",
            "Cost after iteration 0: 0.334307\n",
            "Cost after iteration 0: 0.441465\n",
            "Cost after iteration 0: 0.294498\n",
            "Cost after iteration 1: 0.315114\n",
            "Cost after iteration 1: 0.385763\n",
            "Cost after iteration 1: 0.340121\n",
            "Cost after iteration 1: 0.450981\n",
            "Cost after iteration 1: 0.446085\n",
            "Cost after iteration 1: 0.423553\n",
            "Cost after iteration 1: 0.368974\n",
            "Cost after iteration 1: 0.415269\n",
            "Cost after iteration 1: 0.411988\n",
            "Cost after iteration 1: 0.363651\n",
            "Cost after iteration 2: 0.298310\n",
            "Cost after iteration 2: 0.282289\n",
            "Cost after iteration 2: 0.371326\n",
            "Cost after iteration 2: 0.396219\n",
            "Cost after iteration 2: 0.354530\n",
            "Cost after iteration 2: 0.350590\n",
            "Cost after iteration 2: 0.324588\n",
            "Cost after iteration 2: 0.290415\n",
            "Cost after iteration 2: 0.373151\n",
            "Cost after iteration 2: 0.357294\n",
            "Cost after iteration 3: 0.344251\n",
            "Cost after iteration 3: 0.380974\n",
            "Cost after iteration 3: 0.363351\n",
            "Cost after iteration 3: 0.317950\n",
            "Cost after iteration 3: 0.360143\n",
            "Cost after iteration 3: 0.402870\n",
            "Cost after iteration 3: 0.280219\n",
            "Cost after iteration 3: 0.458359\n",
            "Cost after iteration 3: 0.354183\n",
            "Cost after iteration 3: 0.352386\n",
            "Cost after iteration 4: 0.322553\n",
            "Cost after iteration 4: 0.336030\n",
            "Cost after iteration 4: 0.368062\n",
            "Cost after iteration 4: 0.417772\n",
            "Cost after iteration 4: 0.415500\n",
            "Cost after iteration 4: 0.343051\n",
            "Cost after iteration 4: 0.361255\n",
            "Cost after iteration 4: 0.316469\n",
            "Cost after iteration 4: 0.282076\n",
            "Cost after iteration 4: 0.384584\n",
            "Cost after iteration 5: 0.292061\n",
            "Cost after iteration 5: 0.323235\n",
            "Cost after iteration 5: 0.351137\n",
            "Cost after iteration 5: 0.390743\n",
            "Cost after iteration 5: 0.253994\n",
            "Cost after iteration 5: 0.360420\n",
            "Cost after iteration 5: 0.303395\n",
            "Cost after iteration 5: 0.358383\n",
            "Cost after iteration 5: 0.337169\n",
            "Cost after iteration 5: 0.344437\n",
            "Cost after iteration 6: 0.337960\n",
            "Cost after iteration 6: 0.397386\n",
            "Cost after iteration 6: 0.372468\n",
            "Cost after iteration 6: 0.362677\n",
            "Cost after iteration 6: 0.319516\n",
            "Cost after iteration 6: 0.289346\n",
            "Cost after iteration 6: 0.413103\n",
            "Cost after iteration 6: 0.450926\n",
            "Cost after iteration 6: 0.315368\n",
            "Cost after iteration 6: 0.290326\n",
            "Cost after iteration 7: 0.272053\n",
            "Cost after iteration 7: 0.314527\n",
            "Cost after iteration 7: 0.297504\n",
            "Cost after iteration 7: 0.340085\n",
            "Cost after iteration 7: 0.362944\n",
            "Cost after iteration 7: 0.427353\n",
            "Cost after iteration 7: 0.374870\n",
            "Cost after iteration 7: 0.309253\n",
            "Cost after iteration 7: 0.394220\n",
            "Cost after iteration 7: 0.310761\n",
            "Cost after iteration 8: 0.344406\n",
            "Cost after iteration 8: 0.350410\n",
            "Cost after iteration 8: 0.358345\n",
            "Cost after iteration 8: 0.445278\n",
            "Cost after iteration 8: 0.340689\n",
            "Cost after iteration 8: 0.422715\n",
            "Cost after iteration 8: 0.400877\n",
            "Cost after iteration 8: 0.387188\n",
            "Cost after iteration 8: 0.311135\n",
            "Cost after iteration 8: 0.366018\n",
            "Cost after iteration 9: 0.404208\n",
            "Cost after iteration 9: 0.364257\n",
            "Cost after iteration 9: 0.287145\n",
            "Cost after iteration 9: 0.317646\n",
            "Cost after iteration 9: 0.338503\n",
            "Cost after iteration 9: 0.295350\n",
            "Cost after iteration 9: 0.517783\n",
            "Cost after iteration 9: 0.289036\n",
            "Cost after iteration 9: 0.305209\n",
            "Cost after iteration 9: 0.386534\n",
            "Cost after iteration 10: 0.381697\n",
            "Cost after iteration 10: 0.324266\n",
            "Cost after iteration 10: 0.386073\n",
            "Cost after iteration 10: 0.419663\n",
            "Cost after iteration 10: 0.425630\n",
            "Cost after iteration 10: 0.234540\n",
            "Cost after iteration 10: 0.316391\n",
            "Cost after iteration 10: 0.293790\n",
            "Cost after iteration 10: 0.308362\n",
            "Cost after iteration 10: 0.289367\n",
            "Cost after iteration 11: 0.307445\n",
            "Cost after iteration 11: 0.292326\n",
            "Cost after iteration 11: 0.303295\n",
            "Cost after iteration 11: 0.365346\n",
            "Cost after iteration 11: 0.277699\n",
            "Cost after iteration 11: 0.341183\n",
            "Cost after iteration 11: 0.423650\n",
            "Cost after iteration 11: 0.389103\n",
            "Cost after iteration 11: 0.263557\n",
            "Cost after iteration 11: 0.326520\n",
            "Cost after iteration 12: 0.293232\n",
            "Cost after iteration 12: 0.447989\n",
            "Cost after iteration 12: 0.398598\n",
            "Cost after iteration 12: 0.473817\n",
            "Cost after iteration 12: 0.374955\n",
            "Cost after iteration 12: 0.347923\n",
            "Cost after iteration 12: 0.311691\n",
            "Cost after iteration 12: 0.395249\n",
            "Cost after iteration 12: 0.343934\n",
            "Cost after iteration 12: 0.369348\n",
            "Cost after iteration 13: 0.385863\n",
            "Cost after iteration 13: 0.361454\n",
            "Cost after iteration 13: 0.421369\n",
            "Cost after iteration 13: 0.307916\n",
            "Cost after iteration 13: 0.335499\n",
            "Cost after iteration 13: 0.382397\n",
            "Cost after iteration 13: 0.376689\n",
            "Cost after iteration 13: 0.380955\n",
            "Cost after iteration 13: 0.460274\n",
            "Cost after iteration 13: 0.397285\n",
            "Cost after iteration 14: 0.290469\n",
            "Cost after iteration 14: 0.320132\n",
            "Cost after iteration 14: 0.362705\n",
            "Cost after iteration 14: 0.361386\n",
            "Cost after iteration 14: 0.384469\n",
            "Cost after iteration 14: 0.340902\n",
            "Cost after iteration 14: 0.265140\n",
            "Cost after iteration 14: 0.293662\n",
            "Cost after iteration 14: 0.316692\n",
            "Cost after iteration 14: 0.413182\n",
            "Cost after iteration 15: 0.249824\n",
            "Cost after iteration 15: 0.335105\n",
            "Cost after iteration 15: 0.402399\n",
            "Cost after iteration 15: 0.339792\n",
            "Cost after iteration 15: 0.364161\n",
            "Cost after iteration 15: 0.447288\n",
            "Cost after iteration 15: 0.384653\n",
            "Cost after iteration 15: 0.368646\n",
            "Cost after iteration 15: 0.388154\n",
            "Cost after iteration 15: 0.305555\n",
            "Cost after iteration 16: 0.311075\n",
            "Cost after iteration 16: 0.394703\n",
            "Cost after iteration 16: 0.412154\n",
            "Cost after iteration 16: 0.415103\n",
            "Cost after iteration 16: 0.343219\n",
            "Cost after iteration 16: 0.301681\n",
            "Cost after iteration 16: 0.300013\n",
            "Cost after iteration 16: 0.342260\n",
            "Cost after iteration 16: 0.333126\n",
            "Cost after iteration 16: 0.295727\n",
            "Cost after iteration 17: 0.308218\n",
            "Cost after iteration 17: 0.414281\n",
            "Cost after iteration 17: 0.431183\n",
            "Cost after iteration 17: 0.372413\n",
            "Cost after iteration 17: 0.380454\n",
            "Cost after iteration 17: 0.254308\n",
            "Cost after iteration 17: 0.396027\n",
            "Cost after iteration 17: 0.267199\n",
            "Cost after iteration 17: 0.531785\n",
            "Cost after iteration 17: 0.297781\n",
            "Cost after iteration 18: 0.367232\n",
            "Cost after iteration 18: 0.367016\n",
            "Cost after iteration 18: 0.290234\n",
            "Cost after iteration 18: 0.277518\n",
            "Cost after iteration 18: 0.326636\n",
            "Cost after iteration 18: 0.338608\n",
            "Cost after iteration 18: 0.364579\n",
            "Cost after iteration 18: 0.414038\n",
            "Cost after iteration 18: 0.442431\n",
            "Cost after iteration 18: 0.239140\n",
            "Cost after iteration 19: 0.369619\n",
            "Cost after iteration 19: 0.421969\n",
            "Cost after iteration 19: 0.338899\n",
            "Cost after iteration 19: 0.421220\n",
            "Cost after iteration 19: 0.335026\n",
            "Cost after iteration 19: 0.362893\n",
            "Cost after iteration 19: 0.339991\n",
            "Cost after iteration 19: 0.372312\n",
            "Cost after iteration 19: 0.318613\n",
            "Cost after iteration 19: 0.365750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "0GXjhMjXDulA",
        "outputId": "cf077f79-1ef9-4ea4-e224-878a488d6c4b"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(overall_loss, color='blue')\n",
        "plt.plot(overall_accuracy, color='green')\n",
        "plt.xlabel('number of iterations')\n",
        "plt.title('Mini Batch Gradient descent of NN')\n",
        "plt.show()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFwCtZrj9Hen"
      },
      "source": [
        "NN_y_pred = predict(parameters, NN_X_test)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTG-onbh9owY",
        "outputId": "347eabe9-f261-481e-8cf4-0dd61c9cbb39"
      },
      "source": [
        "np.unique(NN_y_pred, return_counts=True)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1]), array([11373,  3687]))"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tRQYdPN25wg",
        "outputId": "b8216aa4-209c-4b13-c234-5191358c6e7e"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, NN_y_pred.squeeze()))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.88      0.89      0.89     11360\n",
            "         1.0       0.65      0.65      0.65      3700\n",
            "\n",
            "    accuracy                           0.83     15060\n",
            "   macro avg       0.77      0.77      0.77     15060\n",
            "weighted avg       0.83      0.83      0.83     15060\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkQYnrevKimI"
      },
      "source": [
        "# **References** \n",
        "\n",
        "https://stackoverflow.com/questions/25427650/sklearn-logisticregression-without-regularization\n",
        "\n",
        "https://stackoverflow.com/questions/48185090/how-to-get-the-log-likelihood-for-a-logistic-regression-model-in-sklearn\n",
        "\n",
        "https://stackoverflow.com/questions/25009284/how-to-plot-roc-curve-in-python\n",
        "\n",
        "https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74"
      ]
    }
  ]
}